{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8e477af",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Task 2.2 Data Visualisation\n",
    "\n",
    "In this task, you will implement a program to visualize the joined streaming data. For the incoming camera event(s), \n",
    "* plot the number of violation against arrival time. You need to label some interesting points such as maximum and minimum values. \n",
    "* In addition to that, plot the speed against arrival time. You need to include some interesting points such as average and maximum values.\n",
    "\n",
    "For visualization on the data stored in the database, you have to plot a map using camera location. On the map, annotate\n",
    "* number of violations between the checkpoints\n",
    "* identify hotspot (e.g. when number of violations exceed certain threshold within a time in a day)\n",
    "\n",
    "Explain and justify the plots and the inclusion of the interesting points. Set your own threshold for the hotspot.\n",
    "\n",
    "If you are running this task in a separate Jupyter notebook file, save the file as **xxx_assignment02_visualisation.ipynb**, where **xxx** represents the student IDs of the group members."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886a3fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364e85e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data\n",
    "hostip = \"192.168.0.21\"\n",
    "\n",
    "DB_NAME     = \"awas_db\"\n",
    "\n",
    "\n",
    "from pymongo import MongoClient, ASCENDING, HASHED\n",
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql.functions import col, split, element_at, when, from_json, expr, unix_timestamp\n",
    "from pyspark.sql.types import StructType, StringType, IntegerType, DoubleType, TimestampType, StructField\n",
    "from pyspark.sql.streaming.state import GroupState, GroupStateTimeout\n",
    "import os\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = (\n",
    "    \"--packages \"\n",
    "    \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,\"\n",
    "    \"org.apache.spark:spark-streaming-kafka-0-10_2.12:3.5.0,\"\n",
    "    \"org.mongodb.spark:mongo-spark-connector_2.12:10.3.0 \"\n",
    "    \"pyspark-shell\"\n",
    ")\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"AWAS-Speed-Enforcement\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.mongodb.read.connection.uri\", f\"mongodb://{hostip}:27017/{DB_NAME}\") \\\n",
    "    .config(\"spark.mongodb.write.connection.uri\", f\"mongodb://{hostip}:27017/{DB_NAME}\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "eventSchema = (StructType()\n",
    "    .add(\"event_id\", StringType())\n",
    "    .add(\"car_plate\", StringType()) \n",
    "    .add(\"camera_id\", IntegerType()) \n",
    "    .add(\"timestamp\", TimestampType()) \n",
    "    .add(\"speed_reading\", DoubleType()) \n",
    "    .add(\"producer\", StringType()))\n",
    "\n",
    "df = spark.readStream.schema(eventSchema).format(\"json\").load(\"path_to_incoming_joined_stream\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3b82e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No of violation vs Arrival time\n",
    "def visualisation():\n",
    "    try:\n",
    "        data = df.select(\n",
    "            col(\"timestamp\").alias(\"arrival_time\"),\n",
    "            when(col(\"speed_reading\") > 60, 1).otherwise(0).alias(\"violation\")\n",
    "        ).groupBy(\"arrival_time\").sum(\"violation\").orderBy(\"arrival_time\")\n",
    "        data = data.toPandas() \n",
    "        # data.set_index(\"arrival_time\", inplace=True)  # Set arrival_time as index   \n",
    "        # data.columns = [\"num_violations\"]  # Rename column for clarity\n",
    "        # data = data.reset_index()  # Reset index to have arrival_time as a column\n",
    "        # # Plotting\n",
    "        # plt.close('all')  # Close any existing plots\n",
    "        # plt.style.use('ggplot')  # Use ggplot style for better aesthetics\n",
    "        # # Create a new figure with specified size\n",
    "\n",
    "        width = 9.5\n",
    "        height = 6\n",
    "        fig = plt.figure(figsize=(width, height)) # new figure\n",
    "        ax = fig.add_subplot(111)  # add subplot axes\n",
    "        fig.suptitle(\"Number of Violations vs Arrival Time\")\n",
    "        ax.set_xlabel(\"Arrival Time (in seconds)\")\n",
    "        ax.set_ylabel(\"Number of Violations\")\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
